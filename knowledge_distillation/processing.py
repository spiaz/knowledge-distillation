# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_processing.ipynb (unless otherwise specified).

__all__ = ['scale_onehot', 'split_with_seed', 'evaluate_model']

# Cell
import numpy as np
import pandas as pd
from sklearn.ensemble import StackingClassifier
from sklearn.dummy import DummyClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

from category_encoders import OneHotEncoder, OrdinalEncoder
from sklearn_pandas import DataFrameMapper, gen_features

from .io import *

# Cell

def scale_onehot(df, target):
    """Perform basic scaling and one-hot encoding"""

    features = df.drop(target, axis=1)

    categorical_cols = [[f] for f in features.select_dtypes('object').columns]
    categorical_pipe = gen_features(
        columns=categorical_cols,
        classes=[{'class':SimpleImputer, 'strategy':'constant', 'fill_value':'Na'},
                 OneHotEncoder
                ])

    numerical_cols = [[f] for f in features.select_dtypes('number').columns]
    numerical_pipe = gen_features(
        columns=numerical_cols,
        classes=[SimpleImputer, StandardScaler]
    )

    mapper = DataFrameMapper(categorical_pipe + numerical_pipe, df_out=True)

    X = mapper.fit_transform(df)

    y = df[target]

    target_names = sorted(y.unique())

    y = pd.Categorical(y, categories=target_names, ordered=True)
    y = y.codes

    return X, y, target_names

# Cell

def split_with_seed(X, y, test_size=.2):
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=test_size,
        random_state=42)

    return X_train, X_test, y_train, y_test


# Cell

def evaluate_model(X_train, X_test, y_train, y_test, model, model_name, save_to_disk, print_report=True, target_names=None):
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # if the y input is 2D (ie. one-hot encoded input), convert it to 1D
    if y_train.ndim > 1:
        y_train = np.nonzero(y_train)[1]
        y_test = np.nonzero(y_test)[1]

    elif y_train_pred.ndim > 1:
        # if the y input is 2D (ie. one-hot encoded target), convert it to 1D
        y_train_pred = np.nonzero(y_train_pred)[1]
        y_test_pred = np.nonzero(y_test_pred)[1]

    preds = [(y_train, y_train_pred), (y_test, y_test_pred)]

    df = pd.DataFrame(
        dict(
            model_name = [model_name, model_name],
            data = ['train', 'test'],
            accuracy = [accuracy_score(y_true, y_pred) for y_true, y_pred in preds],
            precision = [precision_score(y_true, y_pred) for y_true, y_pred in preds],
            recall = [recall_score(y_true, y_pred) for y_true, y_pred in preds],
            f1 = [f1_score(y_true, y_pred) for y_true, y_pred in preds],
            auc = [roc_auc_score(y_true, y_pred) for y_true, y_pred in preds],
        )
    )

    df.to_csv(ASSETS_PATH / f"{model_name}_evaluation.csv", index=False)
    if print_report:
        print("=== Train ===")
        print(classification_report(*preds[0], labels=[0, 1], target_names=target_names))
        print("\n=== Test ===")
        print(classification_report(*preds[1], labels=[0, 1], target_names=target_names))
        print()

    return df